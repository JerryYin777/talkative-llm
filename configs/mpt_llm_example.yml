framework: "mpt"



mode: "AutoModelForCausalLM"
model: "mosaicml/mpt-7b-instruct"
device: "cuda"
batch_size: 20
skip_special_tokens: true

# Please do check the documentation: c.f. https://huggingface.co/mosaicml/mpt-7b
params:
  max_new_tokens: 2048
  early_stopping: true
  num_beams: 3
  temperature: 1.0
  top_p: None
  top_k: None
  num_return_sequences: 1